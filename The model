# import necessary modules

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.linear_model import BayesianRidge
from sklearn.metrics import mean_squared_error
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
import seaborn as sns
sns.set(color_codes=True)


# define a file to save the coefficients
coefs_results = open('coefs_results.csv','w')
coefs_results.write("Results of coefficients\n")

# define a file to save the R2
score_r2 = open('score_r2.csv','w')
score_r2.write("Results of the coefficient of determination\n")

# define a file to save the mean squared error
m_s_e = open('mse.csv','w')
m_s_e.write("Results of the mean squared error\n")

# define a file to save the intercept
intercept = open('intercept.csv','w')
intercept.write("Results of the intercept\n")


# define a file to save precision of the noise
alpha = open('alpha.csv','w')
alpha.write("Results of the alpha\n")

# define a file to save estimated precision of the weights
lambd = open('lambda.csv','w')
lambd.write("Results of the lambda\n")

#load the data
path = './IDPs.csv'
data = pd.read_csv(path, sep=' ')
print(data.shape)

#print(data.head())

# check if there is missing values and save the summary in a file
null_values = open('null_values.csv','w')
null_values.write("Summary of null values for all features\n")
null_values.write(str(data.isnull().sum().sum()))


# split the data into features and target. x_raw is the features and y_raw is the target
x_raw = data.drop(['f.eid','f.21003.0.0'] , axis = 1)

print (x_raw.shape)
y_raw = data['f.21003.0.0']
print(y_raw.shape)


# plot the distribution of the target (Age)
sns.distplot(y_raw);
plt.title('Distribution of age', fontsize=12)
plt.xlabel('Age')
plt.ylabel('Frequencies')
plt.savefig('dofage.png')
plt.show()

'''
# another kind of plot 
plt.hist(Y, bins = 14)
plt.xlabel('Age')
plt.ylabel('Frequencies')
plt.title('Distribution of Age')
plt.savefig('dofage.png')
plt.show()
'''


# features preprocessing
x_norm= preprocessing.normalize(x_raw)
std = StandardScaler()
Xs = std.fit_transform(x_norm)

# target preprocessing
y_raw = y_raw.values.reshape(1, -1) 
Y= preprocessing.normalize(y_raw)
Y = Y.ravel()
print(Y.shape)

n_feature = Xs.shape[1]
print (n_feature)

#define number of folds
cv = 10
kf = KFold(n_splits=cv)


# define some arrays if we want to print the results on the screen
mse, coefs, score, interc, alfa, lam, iteration = [], [], [], [], [], [], []

for train, test in kf.split(Xs, Y):
    #Write explanation sentence for each file to understand the results
    coefs_results.write('Coefficients for fold :'+str(cv)+"\n")
    score_r2.write('R2 for fold :'+str(cv)+"\t")
    m_s_e.write("The mean squared error for fold :"+str(cv)+"\t")
    intercept.write("The intercept for fold :"+str(cv)+"\t")
    alpha.write("The estimated precision of the noise for fold :"+str(cv)+"\t")
    lambd.write("The estimated precision of the weights for fold :"+str(cv)+"\t")
    
    
    # define the model
    Breg = BayesianRidge(n_iter = 500, verbose = True, tol=0.0000001)
    
    # fit the data to the model
    Breg.fit(Xs[train], Y[train])
    
    # calculate R2 for each fold and save the value into a file
    score.append(Breg.score(Xs[train], Y[train]))
    print("R2 for fold "+str(cv)+": " '%.8f' % Breg.score(Xs[train], Y[train]))
    
    score_r2.write(str(Breg.score(Xs[train], Y[train]))+"\n")
    
    # predict new values
    ypred = Breg.predict(Xs[test])
    
    # calculate mean squared error for each fold and save into a file
    mse.append(mean_squared_error(Y[test], ypred))
    print("Mean Squared Error for fold "+str(cv)+": " '%.8f' % mean_squared_error(Y[test], ypred))
    m_s_e.write(str(mean_squared_error(Y[test], ypred))+"\n")
    
    # calculate intercept for each fold and save them into a file
    interc.append(Breg.intercept_)
    intercept.write(str(Breg.intercept_)+"\n")
    
    # calclate estimated precision of the noise for each fold and save them into a file
    alfa.append(Breg.alpha_)
    alpha.write(str(Breg.alpha_)+"\n")
    
    # calculate estimated precision of the weights for each fold and save them into a file
    lam.append(Breg.lambda_)
    lambd.write(str(Breg.lambda_)+"\n")
    
    # save the number of iteration till w convergted
    iteration.append(Breg.n_iter)
    
    # print Coefficient word into a file
    for i in range(n_feature):
        coefs_results.write('Coefficient '+str(i+1)+' for the feature '+str(data.columns[i+1]))
        coefs_results.write("\t")
    coefs_results.write("\n")
    
    # calculate Coefficient values for each fold and save them into a file
    for n in range(n_feature):
        coefs.append(Breg.coef_[n])
        coefs_results.write(str(Breg.coef_[n]))
        coefs_results.write("\t")
    cv = cv-1
    coefs_results.write("\n")

'''
# print results on the screen      
print(mse)
print(coefs)
print(score)
print (interc)
print(alfa)
print(lam)
print(iteration)
'''
